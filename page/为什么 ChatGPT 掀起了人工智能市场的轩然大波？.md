人工智能（AI）研究和部署公司 OpenAI 最近宣布全新对话式 AI 模型 ChatGPT 正式上线。据 OpenAI 称，该平台提供的对话使 ChatGPT 有可能“回答后续问题，承认自己的错误，质疑错误的前提，拒绝不恰当的请求。”

自 ChatGPT 上线以来，社交媒体一直在热议这个“新出炉”的创新成果可能带来的机遇与挑战——从它能够调试代码到可能替大学生写论文，无所不谈。我们与 Gartner 研究副总裁 Bern Elliot 和 Gartner 研究总监闫斌一起探讨了这项创新的深远影响，以及数据和分析（D&A）领导者为确保此类工具用于正当用途应采取的行动。

## ChatGPT 的独特之处

### 为什么 ChatGPT 引起了如此大的反响？

ChatGPT 是聊天机器人和 GPT-3 这两个当下“热门”AI 技术的完美结合体。两者结合后，可以进行非常有趣的互动并生成类似人类的回答。这些技术都是过去五年各自领域的重大成果。

聊天机器人能够以一种看似“智能”的对话方式进行互动，而 GPT-3 输出的结果看起来似乎已经能够“理解”问题、内容和上下文。两者的结合创造了不可思议的“恐怖谷”效应：它到底是人还是计算机？或者说它是一个类似人类的计算机？这种互动时而幽默，时而深刻，时而充满见地。

然而，ChatGPT 的回答有时也会出错，且不像是基于人类的理解或智慧所做出的回复。问题可能出在“理解”和“智能”这两个词上。这两个词本身就隐藏着人类赋予的含义，所以当它们被应用于算法时，会产生严重的误解。更务实的观点认为，聊天机器人和像 GPT 这样的大型语言模型（LLM）应被视为完成特定任务的实用工具，而不是用来博人眼球。其成败取决于能否为企业机构带来实际收益。

## ChatGPT 的潜在用例

### ChatGPT 在企业中的应用场景

简而言之，聊天机器人或对话助手可以根据信息源设计互动。聊天机器人已经被广泛应用于客户服务、协助技术人员发现问题等场景。

ChatGPT 是一个可以与 GPT 信息源互动（聊天）或“交谈”的特殊聊天机器人。为此，OpenAI 会针对特定领域训练 GPT 信息源。该模型回答问题的方式取决于所使用的训练数据。但如前所述，GPT 会无征兆地生成错误信息，因此这些信息只能用于可以容忍或纠正错误的场景。

GPT 等基础模型在计算机视觉、软件工程和科学研发等领域的用例众多。例如：
- 从文本中创建图像；
- 从自然语言生成、审查和审计包括智能合约在内的代码；
- 在医疗领域发明新药和破译基因组序列以对疾病进行分类。

## 道德与风险

### ChatGPT 带来的道德担忧

像 GPT 这样的 AI 基础模型代表着 AI 领域的一大进步。它们具有许多优势，比如大幅减少创建特定领域模型所需的成本和时间。但同时也带来了风险和道德方面的担忧，包括：

- **复杂性**：大型模型涉及数十亿乃至数万亿的参数。由于需要耗费巨大的计算资源，这些模型可能变得昂贵且不环保，使得大多数企业无法训练它们。
- **集权**：这些模型主要由拥有庞大研发投入和大量 AI 人才的科技巨头构建。这可能导致权力集中在少数几家企业手中，破坏社会平衡。
- **不正当用途**：基础模型降低了内容创作的成本，使得生成深度伪造品（如语音、视频作假）变得更加容易，可能引发严重的道德问题。
- **黑盒特性**：这些模型的训练过程复杂且不透明，可能会传播数据集中的偏见，甚至引发单点故障。
- **知识产权**：训练模型所使用的语料库可能涉及他人的知识产权，目前尚无明确的法律先例支持这些内容的反复使用。

## 企业如何以道德方式使用 AI 模型？

D&A 领导者可以从以下几个方面入手，以道德的方式将 AI 基础模型融入企业：

1. 从自然语言处理（NLP）用例开始，比如分类、总结和不需要面对客户的场景的文本生成，并选择任务专用的预训练模型以避免昂贵的定制和训练。
2. 优先选择输出结果由人类审核的用例。
3. 创建战略文件，概述 GPT 等 AI 基础模型的优点、风险、机会和布局，以评估具体用例的收益是否大于风险。
4. 使用云端 API 消费模型，选择能够提供高效性能、降低能耗和优化总运营成本的最小模型。
5. 优先选择能够发布使用指南、记录已知漏洞并主动披露有害行为的厂商，以促进负责任的模型部署。

---

👉 [WildCard | 一分钟注册，轻松订阅海外线上服务](https://bit.ly/bewildcard)

---

声明：本文来自 Gartner 公司，版权归作者所有。文章内容仅代表作者独立观点，不代表安全内参立场，转载目的在于传递更多信息。如有侵权，请联系 anquanneican@163.com。